from typing import List, Dict, Any
from ..models.rag_models import ContextItem
from ..models.classification_models import ClassificationRequest, ClassificationResult, QueryType
from ..core.config import settings
from .classification_service import ClassificationService
from .database_service import DatabaseService
from .vector_service import VectorService
from .embedding_service import EmbeddingService

class HybridSearchService:
    """åˆ†é¡ã«åŸºã¥ãçµ±åˆæ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆæœ€é©åŒ–å¯¾å¿œï¼‰"""
    
    def __init__(self) -> None:
        self.classification_service = ClassificationService()
        self.database_service = DatabaseService()
        self.vector_service = VectorService()
        self.embedding_service = EmbeddingService()
    
    async def search(self, query: str, top_k: int = 3) -> Dict[str, Any]:
        """
        ã‚¯ã‚¨ãƒªã‚’åˆ†é¡ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢æˆ¦ç•¥ã§çµæœã‚’å–å¾—
        
        Returns:
            Dict containing:
            - classification: åˆ†é¡çµæœ
            - search_strategy: ä½¿ç”¨ã—ãŸæ¤œç´¢æˆ¦ç•¥
            - db_results: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢çµæœ (if applicable)
            - vector_results: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ (if applicable)
            - merged_results: ãƒãƒ¼ã‚¸ã•ã‚ŒãŸæœ€çµ‚çµæœ
            - search_quality: æ¤œç´¢å“è³ªè©•ä¾¡
        """
        print("=== æœ€é©åŒ–çµ±åˆæ¤œç´¢é–‹å§‹ ===")
        print(f"ã‚¯ã‚¨ãƒª: {query}")
        
        # Step 1: LLMã«ã‚ˆã‚‹åˆ†é¡ãƒ»è¦ç´„
        classification = await self._classify_query(query)
        
        # æŒ¨æ‹¶ã®å ´åˆã¯æ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if self._is_greeting(classification):
            return self._create_greeting_response(classification)
        
        # Step 2: æ¤œç´¢æˆ¦ç•¥ã®æ±ºå®šã¨æœ€é©åŒ–
        search_strategy = self.classification_service.determine_search_strategy(classification)
        optimized_limits = self._get_optimized_limits(classification, top_k)
        
        print(f"æ¤œç´¢æˆ¦ç•¥: DB={search_strategy.use_db_filter}, Vector={search_strategy.use_vector_search}")
        print(f"æœ€é©åŒ–é™ç•Œ: {optimized_limits}")
        
        # Step 3: å„æ¤œç´¢ã®å®Ÿè¡Œ
        db_results, vector_results = await self._execute_searches(
            classification, search_strategy, optimized_limits, query
        )
        
        # Step 4: çµæœã®å“è³ªè©•ä¾¡
        search_quality = self._evaluate_search_quality(
            db_results, vector_results, classification
        )
        
        # Step 5: æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ»é¸æŠ
        merged_results = self._merge_results_optimized(
            db_results, vector_results, classification, top_k, search_quality
        )
        
        print(f"æœ€çµ‚çµæœ: {len(merged_results)}ä»¶")
        print(f"æ¤œç´¢å“è³ª: {search_quality}")
        
        return {
            "classification": classification,
            "search_strategy": search_strategy,
            "db_results": db_results,
            "vector_results": vector_results,
            "merged_results": merged_results,
            "search_quality": search_quality,
            "optimization_applied": True
        }

    async def _classify_query(self, query: str) -> ClassificationResult:
        """ã‚¯ã‚¨ãƒªã‚’åˆ†é¡ã™ã‚‹"""
        classification_request = ClassificationRequest(query=query)
        classification = await self.classification_service.classify_query(classification_request)
        
        print(f"åˆ†é¡çµæœ: {classification.query_type}")
        print(f"è¦ç´„: {classification.summary}")
        print(f"ä¿¡é ¼åº¦: {classification.confidence}")
        
        # ClassificationResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        if not isinstance(classification, ClassificationResult):
            raise ValueError("Classification service returned unexpected type")
        
        return classification

    def _is_greeting(self, classification: ClassificationResult) -> bool:
        """æŒ¨æ‹¶ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        return classification.query_type == QueryType.GREETING

    def _create_greeting_response(self, classification: ClassificationResult) -> Dict[str, Any]:
        """æŒ¨æ‹¶ç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ"""
        print("=== æŒ¨æ‹¶æ¤œå‡º: æ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ— ===")
        return {
            "classification": classification,
            "search_strategy": {
                "use_database": False,
                "use_vector": False,
                "skip_search": True,
                "reason": "greeting_detected"
            },
            "db_results": [],
            "vector_results": [],
            "merged_results": [],
            "search_quality": {
                "overall_score": 1.0,
                "greeting_detected": True,
                "search_needed": False
            }
        }

    async def _execute_searches(
        self, 
        classification: ClassificationResult, 
        search_strategy: Any, 
        optimized_limits: Dict[str, int],
        query: str
    ) -> tuple[List[ContextItem], List[ContextItem]]:
        """å„æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹"""
        db_results = []
        vector_results = []
        
        if search_strategy.use_db_filter and classification.filter_keywords:
            print("--- æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œç´¢å®Ÿè¡Œ ---")
            db_limit = optimized_limits["db_limit"]
            db_results = await self.database_service.filter_search(
                classification.filter_keywords, db_limit
            )
            print(f"DBæ¤œç´¢çµæœ: {len(db_results)}ä»¶")
        
        if search_strategy.use_vector_search:
            print("--- æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«æ„å‘³æ¤œç´¢å®Ÿè¡Œ ---")
            # åˆ†é¡çµæœã«åŸºã¥ãæœ€é©åŒ–ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            query_embedding = await self.embedding_service.get_embedding_from_classification(
                query, classification
            )
            
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
            vector_limit = optimized_limits["vector_limit"]
            vector_results = await self.vector_service.search(
                query_embedding, 
                top_k=vector_limit,
                classification=classification
            )
            print(f"ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ: {len(vector_results)}ä»¶")
        
        return db_results, vector_results
    
    def _get_optimized_limits(self, classification: ClassificationResult, top_k: int) -> Dict[str, int]:
        """åˆ†é¡çµæœã«åŸºã¥ã„ã¦æ¤œç´¢é™ç•Œã‚’æœ€é©åŒ–"""
        
        config = settings.VECTOR_SEARCH_CONFIG["search_limits"]
        
        # å‹å®‰å…¨ãªconfigè¾æ›¸ã‚¢ã‚¯ã‚»ã‚¹
        if isinstance(config, dict) and classification.query_type.value in config:
            limits = config[classification.query_type.value]
            if isinstance(limits, dict):
                vector_limit = limits.get("vector", 15)
                db_limit = limits.get("db", 5)
            else:
                vector_limit = 15
                db_limit = 5
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            vector_limit = 10
            db_limit = 10
        
        # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹èª¿æ•´
        if classification.confidence >= 0.8:
            # é«˜ä¿¡é ¼åº¦ã®å ´åˆã€ã‚ˆã‚Šå¤šãã®çµæœã‚’å–å¾—
            vector_limit = int(vector_limit * 1.2)
            db_limit = int(db_limit * 1.2)
        elif classification.confidence < 0.5:
            # ä½ä¿¡é ¼åº¦ã®å ´åˆã€çµæœã‚’çµã‚‹
            vector_limit = max(5, int(vector_limit * 0.8))
            db_limit = max(5, int(db_limit * 0.8))
        
        return {
            "vector_limit": vector_limit,
            "db_limit": db_limit
        }
    
    def _evaluate_search_quality(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        classification: ClassificationResult
    ) -> Dict[str, Any]:
        """æ¤œç´¢çµæœã®å“è³ªã‚’è©•ä¾¡"""
        
        quality = {
            "overall_score": 0.0,
            "db_quality": 0.0,
            "vector_quality": 0.0,
            "result_count": len(db_results) + len(vector_results),
            "has_high_confidence_results": False,
            "avg_score": 0.0
        }
        
        all_scores = []
        
        # DBçµæœã®å“è³ªè©•ä¾¡
        if db_results:
            db_scores = [result.score for result in db_results if result.score > 0]
            if db_scores:
                quality["db_quality"] = sum(db_scores) / len(db_scores)
                all_scores.extend(db_scores)
        
        # ãƒ™ã‚¯ãƒˆãƒ«çµæœã®å“è³ªè©•ä¾¡
        if vector_results:
            vector_scores = [result.score for result in vector_results if result.score > 0]
            if vector_scores:
                quality["vector_quality"] = sum(vector_scores) / len(vector_scores)
                all_scores.extend(vector_scores)
        
        # å…¨ä½“è©•ä¾¡
        if all_scores:
            quality["avg_score"] = sum(all_scores) / len(all_scores)
            quality["has_high_confidence_results"] = any(score > 0.8 for score in all_scores)
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆåˆ†é¡ä¿¡é ¼åº¦ã‚‚è€ƒæ…®ï¼‰
            base_score = quality["avg_score"]
            confidence_bonus = classification.confidence * 0.1
            result_count_factor = min(1.0, len(all_scores) / 5)  # 5ä»¶ä»¥ä¸Šã§æº€ç‚¹
            
            quality["overall_score"] = (base_score + confidence_bonus) * result_count_factor
        
        return quality
    
    def _merge_results_optimized(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        classification: ClassificationResult,
        top_k: int,
        search_quality: Dict[str, Any]
    ) -> List[ContextItem]:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ­ã‚¸ãƒƒã‚¯"""
        
        # çµæœãŒãªã„å ´åˆã®å‡¦ç†
        if not db_results and not vector_results:
            return self._handle_no_results_optimized(classification)
        
        # å˜ä¸€ã‚½ãƒ¼ã‚¹ã®å ´åˆ
        if not db_results:
            return self._filter_by_quality(vector_results, search_quality, top_k)
        
        if not vector_results:
            return self._filter_by_quality(db_results, search_quality, top_k)
        
        # å“è³ªã«åŸºã¥ããƒãƒ¼ã‚¸æˆ¦ç•¥ã®èª¿æ•´
        if search_quality["overall_score"] < 0.5:
            print("ğŸ” ä½å“è³ªæ¤œå‡º: ã‚ˆã‚Šå¤šãã®çµæœã‚’å«ã‚ã¾ã™")
            # ä½å“è³ªã®å ´åˆã€ã‚ˆã‚Šå¤šãã®çµæœã‚’å«ã‚ã‚‹
            return self._merge_results_inclusive(db_results, vector_results, classification, top_k)
        
        # é€šå¸¸ã®ãƒãƒ¼ã‚¸å‡¦ç†
        return self._merge_results_standard(db_results, vector_results, classification, top_k)
    
    def _merge_results_standard(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        classification: ClassificationResult,
        top_k: int
    ) -> List[ContextItem]:
        """æ¨™æº–çš„ãªãƒãƒ¼ã‚¸å‡¦ç†"""
        
        if classification.query_type == QueryType.HYBRID:
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®å ´åˆã¯é‡ã¿ä»˜ã‘ãƒãƒ¼ã‚¸
            return self._weighted_merge_optimized(db_results, vector_results, top_k)
        elif classification.query_type == QueryType.FILTERABLE:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å„ªå…ˆã®å ´åˆã¯DBã®çµæœã‚’å„ªå…ˆã—ã€ä¸è¶³åˆ†ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è£œå®Œ
            merged = db_results[:top_k]
            if len(merged) < top_k:
                remaining = top_k - len(merged)
                merged.extend(vector_results[:remaining])
            return merged
        else:  # SEMANTIC
            # æ„å‘³æ¤œç´¢å„ªå…ˆã®å ´åˆã¯ãƒ™ã‚¯ãƒˆãƒ«ã®çµæœã‚’å„ªå…ˆã—ã€ä¸è¶³åˆ†ã‚’DBã§è£œå®Œ
            merged = vector_results[:top_k]
            if len(merged) < top_k:
                remaining = top_k - len(merged)
                merged.extend(db_results[:remaining])
            return merged
    
    def _merge_results_inclusive(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        classification: ClassificationResult,
        top_k: int
    ) -> List[ContextItem]:
        """åŒ…æ‹¬çš„ãƒãƒ¼ã‚¸ï¼ˆä½å“è³ªæ™‚ï¼‰"""
        
        all_results = []
        
        # ã™ã¹ã¦ã®çµæœã‚’å«ã‚ã¦ã€ã‚¹ã‚³ã‚¢ã§ä¸¦ã³æ›¿ãˆ
        all_results.extend(db_results)
        all_results.extend(vector_results)
        
        # é‡è¤‡é™¤å»ï¼ˆåŒä¸€ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
        seen_titles = set()
        unique_results = []
        
        for result in all_results:
            if result.title not in seen_titles:
                seen_titles.add(result.title)
                unique_results.append(result)
        
        # ã‚¹ã‚³ã‚¢ã§ä¸¦ã³æ›¿ãˆ
        unique_results.sort(key=lambda x: x.score, reverse=True)
        
        return unique_results[:top_k]
    
    def _weighted_merge_optimized(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        top_k: int
    ) -> List[ContextItem]:
        """æœ€é©åŒ–ã•ã‚ŒãŸé‡ã¿ä»˜ããƒãƒ¼ã‚¸"""
        
        config_merge = settings.VECTOR_SEARCH_CONFIG.get("merge_weights", {})
        if isinstance(config_merge, dict):
            db_weight = config_merge.get("db_weight", 0.4)
            vector_weight = config_merge.get("vector_weight", 0.6)
        else:
            db_weight = 0.4
            vector_weight = 0.6
        
        all_results = []
        
        # DBã®çµæœã«é‡ã¿ä»˜ã‘
        for item in db_results:
            weighted_item = ContextItem(
                title=f"[DB] {item.title}",
                text=item.text,
                score=item.score * db_weight
            )
            all_results.append(weighted_item)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã®çµæœã«é‡ã¿ä»˜ã‘
        for item in vector_results:
            weighted_item = ContextItem(
                title=f"[Vec] {item.title}",
                text=item.text,
                score=item.score * vector_weight
            )
            all_results.append(weighted_item)
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’è¿”ã™
        all_results.sort(key=lambda x: x.score, reverse=True)
        return all_results[:top_k]
    
    def _filter_by_quality(
        self, 
        results: List[ContextItem], 
        search_quality: Dict[str, Any], 
        top_k: int
    ) -> List[ContextItem]:
        """å“è³ªã«åŸºã¥ãçµæœãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        
        config_min_score = settings.VECTOR_SEARCH_CONFIG.get("minimum_score", 0.5)
        if isinstance(config_min_score, (int, float)):
            min_score = float(config_min_score)
        else:
            min_score = 0.5
        
        # æœ€å°ã‚¹ã‚³ã‚¢ä»¥ä¸Šã®çµæœã®ã¿ä¿æŒ
        filtered_results = [
            result for result in results 
            if result.score >= min_score
        ]
        
        if not filtered_results and results:
            # ã™ã¹ã¦ãŒæœ€å°ã‚¹ã‚³ã‚¢æœªæº€ã®å ´åˆã€ä¸Šä½1ä»¶ã¯ä¿æŒ
            print("âš ï¸ å…¨çµæœãŒæœ€å°ã‚¹ã‚³ã‚¢æœªæº€ã®ãŸã‚ã€ä¸Šä½1ä»¶ã‚’ä¿æŒ")
            return [results[0]]
        
        return filtered_results[:top_k]
    
    def _handle_no_results_optimized(self, classification: ClassificationResult) -> List[ContextItem]:
        """æœ€é©åŒ–ã•ã‚ŒãŸçµæœãªã—æ™‚ã®å‡¦ç†"""
        
        print("ğŸ” æ¤œç´¢çµæœæœ€é©åŒ–: è©²å½“ãªã—æ™‚ã®å‡¦ç†")
        
        # åˆ†é¡ã«åŸºã¥ãæœ‰ç”¨ãªææ¡ˆã‚’ç”Ÿæˆ
        suggestion_text = self._generate_search_suggestion(classification)
        
        return [
            ContextItem(
                title="æ¤œç´¢ã®ã”ææ¡ˆ",
                text=suggestion_text,
                score=0.1
            )
        ]
    
    def _generate_search_suggestion(self, classification: ClassificationResult) -> str:
        """æ¤œç´¢ææ¡ˆã‚’ç”Ÿæˆ"""
        
        base_message = "ãŠæ¢ã—ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã‚’ãŠè©¦ã—ãã ã•ã„ï¼š\n\n"
        
        if classification.query_type == QueryType.SEMANTIC:
            suggestions = [
                "â€¢ ã‚ˆã‚Šå…·ä½“çš„ãªãƒã‚±ãƒ¢ãƒ³åã‚„ã‚«ãƒ¼ãƒ‰åã§æ¤œç´¢",
                "â€¢ ã€ŒæŠ€ã€ã€ŒHPã€ã€Œã‚¿ã‚¤ãƒ—ã€ãªã©ã®å…·ä½“çš„ãªå±æ€§ã‚’å«ã‚ãŸæ¤œç´¢",
                "â€¢ ã€Œå¼·ã„è‰ã‚¿ã‚¤ãƒ—ã®ãƒã‚±ãƒ¢ãƒ³ã€ã®ã‚ˆã†ã«æ¡ä»¶ã‚’æ˜ç¢ºåŒ–"
            ]
        
        elif classification.query_type == QueryType.FILTERABLE:
            suggestions = [
                "â€¢ æ•°å€¤æ¡ä»¶ã‚’èª¿æ•´ï¼ˆä¾‹ï¼šHP100ä»¥ä¸Š â†’ HP80ä»¥ä¸Šï¼‰",
                "â€¢ è¤‡æ•°æ¡ä»¶ã‚’å˜ä¸€æ¡ä»¶ã«ç°¡ç´ åŒ–",
                "â€¢ ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚¿ã‚¤ãƒ—ã‚„å±æ€§ã§æ¤œç´¢"
            ]
        
        else:  # HYBRID
            suggestions = [
                "â€¢ æ¤œç´¢æ¡ä»¶ã‚’åˆ†ã‘ã¦æ®µéšçš„ã«æ¤œç´¢",
                "â€¢ ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰é–‹å§‹",
                "â€¢ å…·ä½“çš„ãªæ¡ä»¶ã¨æ„å‘³çš„ãªæ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›"
            ]
        
        return base_message + "\n".join(suggestions)
    
    # ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def _merge_results(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        classification: ClassificationResult,
        top_k: int
    ) -> List[ContextItem]:
        """æ¤œç´¢çµæœã‚’ãƒãƒ¼ã‚¸ã—ã¦æœ€é©ãªçµæœã‚’é¸æŠï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰"""
        
        if not db_results and not vector_results:
            return []
        
        if not db_results:
            return vector_results[:top_k]
        
        if not vector_results:
            return db_results[:top_k]
        
        # ä¸¡æ–¹ã®çµæœãŒã‚ã‚‹å ´åˆã®ãƒãƒ¼ã‚¸æˆ¦ç•¥
        if classification.query_type == "hybrid":
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®å ´åˆã¯é‡ã¿ä»˜ã‘ãƒãƒ¼ã‚¸
            return self._weighted_merge(db_results, vector_results, top_k)
        elif classification.query_type == "filterable":
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å„ªå…ˆã®å ´åˆã¯DBã®çµæœã‚’å„ªå…ˆã—ã€ä¸è¶³åˆ†ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è£œå®Œ
            merged = db_results[:top_k]
            if len(merged) < top_k:
                remaining = top_k - len(merged)
                merged.extend(vector_results[:remaining])
            return merged
        else:  # semantic
            # æ„å‘³æ¤œç´¢å„ªå…ˆã®å ´åˆã¯ãƒ™ã‚¯ãƒˆãƒ«ã®çµæœã‚’å„ªå…ˆã—ã€ä¸è¶³åˆ†ã‚’DBã§è£œå®Œ
            merged = vector_results[:top_k]
            if len(merged) < top_k:
                remaining = top_k - len(merged)
                merged.extend(db_results[:remaining])
            return merged
    
    def _weighted_merge(
        self, 
        db_results: List[ContextItem], 
        vector_results: List[ContextItem],
        top_k: int
    ) -> List[ContextItem]:
        """é‡ã¿ä»˜ããƒãƒ¼ã‚¸ - ã‚¹ã‚³ã‚¢ã‚’æ­£è¦åŒ–ã—ã¦çµ±åˆï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰"""
        all_results = []
        
        # DBã®çµæœã«é‡ã¿ä»˜ã‘ï¼ˆ0.4ï¼‰
        for item in db_results:
            weighted_item = ContextItem(
                title=f"[DB] {item.title}",
                text=item.text,
                score=item.score * 0.4
            )
            all_results.append(weighted_item)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã®çµæœã«é‡ã¿ä»˜ã‘ï¼ˆ0.6ï¼‰
        for item in vector_results:
            weighted_item = ContextItem(
                title=f"[Vec] {item.title}",
                text=item.text,
                score=item.score * 0.6
            )
            all_results.append(weighted_item)
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’è¿”ã™
        all_results.sort(key=lambda x: x.score, reverse=True)
        return all_results[:top_k]
