# main.py
import time
import os
import logging
import random
import asyncio
from datetime import datetime
from typing import Any, AsyncGenerator
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.logging import LoggingIntegration
from prometheus_fastapi_instrumentator import Instrumentator
from prometheus_client import Counter, Histogram
from .routers import rag, streaming, security_admin
from .core.exception_handlers import setup_exception_handlers
from .core.config import settings
from .core.security import SecurityHeadersMiddleware
from .core.rate_limit import RateLimitMiddleware
from .core.database import initialize_database, close_database, database_health_check
from .core.logging import GameChatLogger
from .services.storage_service import StorageService
import threading
from google.cloud import storage  # è¿½åŠ : GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

# é€šä¿¡ãƒ¬ã‚¤ãƒ¤ã®å†—é•·ãƒ­ã‚°æŠ‘åˆ¶
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.INFO)  # ã“ã“ã¯INFOã§ã‚‚æ®‹ã™ä¾¡å€¤ã‚ã‚Š
logging.getLogger("google.cloud").setLevel(logging.WARNING)
logging.getLogger("passlib").setLevel(logging.WARNING)
logging.getLogger("google.cloud").setLevel(logging.WARNING)
logging.getLogger("passlib").setLevel(logging.WARNING)

# SentryåˆæœŸåŒ–
if settings.SENTRY_DSN:
    def traces_sampler(sampling_context: dict[str, Any]) -> float:
        """å‹•çš„ãƒˆãƒ¬ãƒ¼ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ã‚¹ã«åŸºã¥ã„ãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if "wsgi_environ" in sampling_context or "asgi_scope" in sampling_context:
            try:
                # FastAPIã®å ´åˆã€asgi_scopeã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                scope = sampling_context.get("asgi_scope", {})
                path = scope.get("path", "")
                
                # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ä½é »åº¦
                if path in ["/health", "/healthcheck", "/metrics", "/ping"]:
                    return 0.01 if settings.ENVIRONMENT == "production" else 0.1
                
                # é™çš„ãƒªã‚½ãƒ¼ã‚¹ã¯ç›£è¦–ã—ãªã„
                if path.startswith(("/static/", "/_next/", "/favicon.ico")):
                    return 0
                
                # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ä¸­é »åº¦
                if path.startswith("/api/"):
                    return 0.1 if settings.ENVIRONMENT == "production" else 0.5
                
                # ãã®ä»–ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
                return 0.05 if settings.ENVIRONMENT == "production" else 1.0
                
            except Exception:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                return 0.1 if settings.ENVIRONMENT == "production" else 1.0
        
        # ãã®ä»–ã®å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return 0.1 if settings.ENVIRONMENT == "production" else 1.0
    
    def before_send(event: dict[str, Any], hint: dict[str, Any]) -> dict[str, Any] | None:
        """ã‚¨ãƒ©ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        if settings.ENVIRONMENT != "production":
            return event
        
        # ä¸€èˆ¬çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if event.get("exception"):
            exc_values = event["exception"].get("values", [])
            for exc_value in exc_values:
                exc_type = exc_value.get("type", "")
                exc_value_str = exc_value.get("value", "")
                
                # ã‚ˆãã‚ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
                if any(pattern in exc_value_str.lower() for pattern in [
                    "connection reset", "connection aborted", "broken pipe",
                    "timeout", "connection refused", "network is unreachable"
                ]):
                    # 10%ã®ç¢ºç‡ã§é€ä¿¡
                    return event if random.random() < 0.1 else None
                
                # HTTP ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
                if "httpx" in exc_type.lower() or "requests" in exc_type.lower():
                    # HTTP 5xx ã‚¨ãƒ©ãƒ¼ã¯é€ä¿¡ã€4xx ã‚¨ãƒ©ãƒ¼ã¯ä½é »åº¦
                    if "5" in exc_value_str[:3]:
                        return event
                    elif "4" in exc_value_str[:3]:
                        return event if random.random() < 0.2 else None
        
        return event
    
    sentry_sdk.init(
        dsn=settings.SENTRY_DSN,
        integrations=[
            FastApiIntegration(
                transaction_style="endpoint",
                failed_request_status_codes=[500, 502, 503, 504],
            ),
            LoggingIntegration(
                level=logging.INFO,
                event_level=logging.ERROR
            ),
        ],
        environment=settings.ENVIRONMENT,
        traces_sampler=traces_sampler,
        sample_rate=0.8 if settings.ENVIRONMENT == "production" else 1.0,
        send_default_pii=False,
        attach_stacktrace=True,
        before_send=before_send,  # type: ignore[arg-type]
        release=os.getenv("GIT_COMMIT_SHA") or os.getenv("VERCEL_GIT_COMMIT_SHA"),
    )

# ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–
GameChatLogger.configure_logging()

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚¢ãƒ—ãƒªé–‹å§‹æ™‚é–“
app_start_time = time.time()

# ã‚«ã‚¹ã‚¿ãƒ Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹
RAG_QUERY_COUNTER = Counter(
    'gamechat_ai_rag_queries_total', 
    'Total number of RAG queries processed',
    ['method', 'status']
)

RAG_QUERY_DURATION = Histogram(
    'gamechat_ai_rag_query_duration_seconds',
    'Time spent processing RAG queries',
    ['method']
)

DATABASE_OPERATIONS_COUNTER = Counter(
    'gamechat_ai_database_operations_total',
    'Total number of database operations',
    ['operation', 'status']
)

STORAGE_OPERATIONS_COUNTER = Counter(
    'gamechat_ai_storage_operations_total',
    'Total number of storage operations',
    ['operation', 'status']
)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def increment_rag_query_counter(method: str, status: str) -> None:
    """RAGã‚¯ã‚¨ãƒªã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ """
    RAG_QUERY_COUNTER.labels(method=method, status=status).inc()

def observe_rag_query_duration(method: str, duration: float) -> None:
    """RAGã‚¯ã‚¨ãƒªå‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²"""
    RAG_QUERY_DURATION.labels(method=method).observe(duration)

def increment_database_operations_counter(operation: str, status: str) -> None:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ """
    DATABASE_OPERATIONS_COUNTER.labels(operation=operation, status=status).inc()

def increment_storage_operations_counter(operation: str, status: str) -> None:
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ“ä½œã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ """
    STORAGE_OPERATIONS_COUNTER.labels(operation=operation, status=status).inc()

# ãƒ—ãƒ­ã‚»ã‚¹å˜ä½ã®åˆæœŸåŒ–ãƒ•ãƒ©ã‚°
_lifespan_initialized = False
_lifespan_lock = threading.Lock()

@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    global _lifespan_initialized
    logger = logging.getLogger("startup")
    logger.info("ğŸš€ Starting GameChat AI backend...")

    # ãƒ—ãƒ­ã‚»ã‚¹å˜ä½ã§åˆæœŸåŒ–å‡¦ç†ã‚’1å›ã ã‘å®Ÿè¡Œ
    with _lifespan_lock:
        if not _lifespan_initialized:
            # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ
            logger.info("Checking for data directory...")
            try:
                logger.info(f"DATA_DIR: {settings.DATA_DIR}")
                logger.info(f"Current UID: {os.getuid()}, EUID: {os.geteuid()}, GID: {os.getgid()}, EGID: {os.getegid()}")
                parent_dir = os.path.dirname(str(settings.DATA_DIR)) or "/"
                logger.info(f"Parent dir: {parent_dir}")
                if os.path.exists(parent_dir):
                    stat = os.stat(parent_dir)
                    logger.info(f"Parent dir stat: mode={oct(stat.st_mode)}, uid={stat.st_uid}, gid={stat.st_gid}")
                else:
                    logger.warning(f"Parent dir does not exist: {parent_dir}")
                if os.path.exists(str(settings.DATA_DIR)):
                    stat = os.stat(str(settings.DATA_DIR))
                    logger.info(f"DATA_DIR stat: mode={oct(stat.st_mode)}, uid={stat.st_uid}, gid={stat.st_gid}")
                else:
                    logger.info(f"DATA_DIR does not exist yet: {settings.DATA_DIR}")
                if not os.path.exists(str(settings.DATA_DIR)):
                    os.makedirs(str(settings.DATA_DIR), exist_ok=True)
                    logger.info(f"ğŸ“ Created data directory: {settings.DATA_DIR}")
                else:
                    logger.info(f"ğŸ“ Data directory already exists: {settings.DATA_DIR}")
            except Exception as e:
                logger.error(f"âš ï¸ Could not create data directory: {e}", exc_info=True)

            # Cloud Runç’°å¢ƒã§GCSã‹ã‚‰data/data.jsonã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            data_path = None
            if settings.ENVIRONMENT == "production":
                bucket_name = settings.GCS_BUCKET_NAME
                gcs_blob_path = "data/data.json"
                local_path = "/tmp/data.json"
                try:
                    async def download_gcs_file():
                        def _download():
                            client = storage.Client()
                            bucket = client.bucket(bucket_name)
                            blob = bucket.blob(gcs_blob_path)
                            if not blob.exists():
                                raise FileNotFoundError(f"GCSãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: gs://{bucket_name}/{gcs_blob_path}")
                            blob.download_to_filename(local_path)
                        return await asyncio.to_thread(_download)
                    await download_gcs_file()
                    logger.info(f"âœ… GCSã‹ã‚‰data/data.jsonã‚’/tmp/data.jsonã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")
                    data_path = local_path
                except Exception as e:
                    logger.error(f"âŒ GCSã‹ã‚‰ã®data/data.jsonãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}", exc_info=True)
                    raise
            # StorageServiceã‚’åˆæœŸåŒ–ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            logger.info("Initializing StorageService...")
            try:
                if data_path:
                    storage_service = StorageService(data_path=data_path)
                else:
                    storage_service = StorageService()
                logger.info("âœ… StorageService initialized successfully")
                
                # ä¸»è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                data_status = {}
                for file_key in ["data", "convert_data", "embedding_list", "query_data"]:
                    file_path = storage_service.get_file_path(file_key)
                    data_status[file_key] = bool(file_path)
                # extraã®å€¤ã‚’ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å‹ãƒ»dictãƒ»listã®ã¿ã«é™å®š
                safe_data_status = {k: bool(v) for k, v in data_status.items()}
                logger.info("ğŸ“Š Data files availability status:", extra={"data_status": safe_data_status})
                
                # æœ€ä½é™å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
                if not (data_status.get("data") or data_status.get("convert_data")):
                    logger.warning("âš ï¸ No primary data files available. Application may have limited functionality.")
            
            except Exception as e:
                logger.error(f"âŒ StorageService initialization failed: {e}", exc_info=True)
                logger.warning("ğŸ”„ Application will continue with limited functionality")

            # ç’°å¢ƒæƒ…å ±ã¨ãƒ‘ã‚¹è¨­å®šã‚’ãƒ­ã‚°å‡ºåŠ›
            safe_env = {
                "environment": str(settings.ENVIRONMENT),
                "current_directory": str(os.getcwd()),
                "project_root": str(settings.PROJECT_ROOT),
                "data_file_path": str(settings.DATA_FILE_PATH),
                "converted_data_path": str(settings.CONVERTED_DATA_FILE_PATH),
                "data_file_exists": bool(os.path.exists(settings.DATA_FILE_PATH)),
                "converted_data_exists": bool(os.path.exists(settings.CONVERTED_DATA_FILE_PATH)),
                "data_dir_exists": bool(os.path.exists(str(settings.DATA_DIR))),
                "data_dir_contents": os.listdir(str(settings.DATA_DIR)) if os.path.exists(str(settings.DATA_DIR)) else "N/A"
            }
            logger.info("ğŸ“ Environment and Path Configuration:", extra=safe_env)

            _lifespan_initialized = True

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–
    logger.info("Initializing database connections...")
    try:
        await initialize_database()
        logger.info("âœ… Database connections initialized successfully")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize database connections: {e}", exc_info=True)

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ—ãƒªã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼‰
    logger.info("Starting cache prewarming task setup...")
    try:
        from .core.cache import prewarmed_query_cache
        from .services.rag_service import RagService
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ—ãƒªã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
        async def background_prewarm() -> None:
            logger.info("ğŸ”¥ Background prewarming task waiting to start...")
            await asyncio.sleep(5)
            logger.info("ğŸ”¥ Starting background cache prewarming process...")
            try:
                logger.info("Instantiating RagService for prewarming...")
                rag_service = RagService()
                logger.info("âœ… RagService instantiated. Starting cache prewarm...")
                await prewarmed_query_cache.prewarm_cache(rag_service)
                logger.info("âœ… Cache prewarming completed successfully.")
            except Exception as e:
                logger.error(f"âŒ Cache prewarming failed during execution: {e}", exc_info=True)
        
        asyncio.create_task(background_prewarm())
        logger.info("âœ… Cache prewarming task created and started.")
    except Exception as e:
        logger.error(f"âŒ Could not start cache prewarming task: {e}", exc_info=True)
    
    logger.info("ğŸ‰ GameChat AI backend started successfully")
    
    yield  # ã“ã“ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿè¡Œã•ã‚Œã‚‹
    
    # çµ‚äº†æ™‚ã®å‡¦ç†
    logger = logging.getLogger("shutdown")
    logger.info("ğŸ›‘ Shutting down GameChat AI backend...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«çµ‚äº†
    try:
        await close_database()
        logger.info("âœ… Database connections closed")
    except Exception as e:
        logger.error(f"âŒ Error closing database connections: {e}")
    
    logger.info("ğŸ‘‹ GameChat AI backend shutdown complete")

app = FastAPI(
    title="GameChat AI API",
    description="GameChat AI Backend API",
    version="1.0.0",
    debug=settings.DEBUG,
    lifespan=lifespan
)

# Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­å®š
instrumentator = Instrumentator(
    should_group_status_codes=False,
    should_ignore_untemplated=True,
    should_respect_env_var=True,
    should_instrument_requests_inprogress=True,
    excluded_handlers=["/health", "/metrics"],
    env_var_name="ENABLE_METRICS",
    inprogress_name="gamechat_ai_requests_inprogress",
    inprogress_labels=True,
)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆæœŸåŒ–ã—ã¦å…¬é–‹
instrumentator.instrument(app).expose(app)

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’è¿½åŠ 
app.add_middleware(SecurityHeadersMiddleware)

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’è¿½åŠ 
app.add_middleware(RateLimitMiddleware)

# çµ±ä¸€ä¾‹å¤–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
setup_exception_handlers(app)

# CORSè¨­å®šã‚’ç’°å¢ƒåˆ¥ã«é©ç”¨
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

import sys

try:
    from .core.config import settings
except Exception as e:
    import traceback
    print("[FATAL] settings import/init failed:", file=sys.stderr)
    traceback.print_exc()
    from .core.config import Settings  # å‹ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚
    class DummySettings(Settings):
        ENVIRONMENT = "unknown"
        DEBUG = False
        CORS_ORIGINS = ["*"]
    settings = DummySettings()

@app.get("/health")
async def health_check() -> dict[str, str | int | float]:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        current_time = time.time()
        uptime = current_time - app_start_time
        return {
            "status": "healthy",
            "service": "gamechat-ai-backend",
            "timestamp": datetime.now().isoformat(),
            "uptime_seconds": round(uptime, 2),
            "version": "1.0.0",
            "environment": settings.ENVIRONMENT
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "service": "gamechat-ai-backend",
            "timestamp": datetime.now().isoformat(),
        }

@app.get("/health/detailed")
async def detailed_health_check() -> dict[str, Any]:
    """è©³ç´°ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    current_time = time.time()
    uptime = current_time - app_start_time
    is_test_mode = os.getenv("TEST_MODE", "false").lower() == "true"
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçŠ¶æ³ã‚’ç¢ºèª
    try:
        if is_test_mode:
            db_health = {"status": "test_mode", "message": "Database checks skipped in test mode"}
        else:
            db_health = await database_health_check()
    except Exception as e:
        db_health = {"status": "error", "message": str(e)}
    
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ã‚’ç¢ºèª
    try:
        storage_service = StorageService()
        storage_health: dict[str, Any] = {
            "status": "healthy" if not is_test_mode else "test_mode",
            "gcs_configured": bool(storage_service.bucket_name) if not is_test_mode else False,
            "environment": settings.ENVIRONMENT,
            "test_mode": is_test_mode
        }
        
        if not is_test_mode:
            storage_health["cache_info"] = storage_service.get_cache_info()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å¯ç”¨æ€§ç¢ºèª
            data_files = {}
            for file_key in ["data", "convert_data", "embedding_list", "query_data"]:
                file_path = storage_service.get_file_path(file_key)
                data_files[file_key] = bool(file_path)
            
            storage_health["data_files"] = data_files
        
    except Exception as e:
        storage_health = {"status": "error", "message": str(e), "test_mode": is_test_mode}
    
    health_data = {
        "status": "healthy",
        "service": "gamechat-ai-backend",
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": round(uptime, 2),
        "version": "1.0.0",
        "environment": settings.ENVIRONMENT,
        "test_mode": is_test_mode,
        "settings": {
            "gcs_bucket_name": settings.GCS_BUCKET_NAME if not is_test_mode else "test-mode",
            "data_dir": str(settings.DATA_DIR)
        },
        "checks": {
            "database": db_health,
            "external_apis": "test_mode" if is_test_mode else "healthy",
            "storage": storage_health
        }
    }
    
    return health_data

@app.get("/health/metrics")
async def metrics_health_check() -> dict[str, Any]:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†çŠ¶æ³ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "service": "gamechat-ai-backend-metrics",
        "timestamp": datetime.now().isoformat(),
        "metrics_endpoint": "/metrics",
        "custom_metrics": {
            "rag_queries": "gamechat_ai_rag_queries_total",
            "rag_duration": "gamechat_ai_rag_query_duration_seconds",
            "database_ops": "gamechat_ai_database_operations_total",
            "storage_ops": "gamechat_ai_storage_operations_total"
        },
        "instrumentator": {
            "enabled": True,
            "inprogress_tracking": True,
            "excluded_handlers": ["/health", "/metrics"]
        }
    }

app.include_router(rag.router, prefix="/api")
app.include_router(streaming.router, prefix="/api")
app.include_router(security_admin.router, prefix="/api/security")